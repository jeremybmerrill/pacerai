{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see README for how I generated the first set of training data (via Prodigy)\n",
    "\n",
    "this is how I'm generating training data from the RSS database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremybmerrill/.pyenv/versions/3.8.2/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from os import environ, makedirs\n",
    "from os.path import join, exists, dirname\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import logging\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from os import environ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "live_engine = create_engine(environ.get(\"LIVE_DATABASE_URL\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_WARRANT_CSV_FN = 'search_warrants_model_training/search_warrants_for_ner_from_rss.csv'\n",
    "with open(SEARCH_WARRANT_CSV_FN, 'w') as outcsv:\n",
    "    writer = None\n",
    "            \n",
    "    sw_docs = pd.read_sql(\"\"\"select case_name, min(document_type) document_type, case_number, court from rss_docket_entries where substring(case_number, 6, 2) = 'sw' group by case_name, case_number, court\"\"\", live_engine)\n",
    "    for i, result in sw_docs.iterrows():\n",
    "        if not writer:\n",
    "            writer = csv.DictWriter(outcsv, fieldnames=result.to_dict().keys())\n",
    "            writer.writeheader()\n",
    "        writer.writerow(result.to_dict())\n",
    "\n",
    "    csvs = [\n",
    "            \"search_warrants_model_training/search warrant training data - rss_document_types_all_courts.csv\", \n",
    "    ]\n",
    "    for csvfn in csvs:\n",
    "        rows = pd.read_csv(csvfn)\n",
    "        rows = rows[rows[\"is search warrant?\"]]\n",
    "        rows = rows[[\"case_name\", \"document_type\", \"case_number\", \"court\"]]\n",
    "        for i, result in rows.iterrows():\n",
    "            if not writer:\n",
    "                writer = csv.DictWriter(outcsv, fieldnames=result.to_dict().keys())\n",
    "                writer.writeheader()\n",
    "            writer.writerow(result.to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA v. Information associated with cell phone numbers (616) 655-3515 and (616) 329-7652,Application and Affidavit for Search/Seizure Warrant,1:21-mj-00263-1,miwd\r",
      "\r\n",
      "USA v. Information,Search Warrant Returned Executed,1:21-mj-00076-1,vawd\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!grep 'USA v. Information' search_warrants_model_training/search_warrants_for_ner_from_rss.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what can we ignore from the starts of the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "examples = []\n",
    "with open(\"search_warrants_model_training/ner_search_warrant_objects.train.json\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        examples.append(' '.join(json.loads(line)[\"tokens\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Application and Affidavit for Search and Seizure Warrant entered ', 53),\n",
       " ('Application for Search Warrant ', 26),\n",
       " ('Application & Affidavit for Search Warrant ', 23),\n",
       " ('APPLICATION and Affidavit for Search Warrant by USA ', 20),\n",
       " ('Application and Affidavit for a Search Warrant ', 16),\n",
       " ('Search and Seizure Warrant Issued in case ', 14),\n",
       " ('APPLICATION AND AFFIDAVIT for Search Warrant ', 14),\n",
       " ('APPLICATION AND AFFIDAVIT by USA ', 12),\n",
       " ('APPLICATION and Affidavit for Search Warrant ', 11),\n",
       " ('APPLICATION and Affidavit for Search Warrant - SEALED ', 8)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "Counter([re.split(r'as to', eg, 1)[0] for eg in examples]).most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
